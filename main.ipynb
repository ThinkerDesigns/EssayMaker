{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4224"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (open(\"sonnets.txt\").read())\n",
    "text = text.lower().split()\n",
    "text.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "numToChar = {n:word for n, word in enumerate(chars)}\n",
    "charToNum = {word:n for n, word in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "length = len(text)\n",
    "lengthSeq = 100\n",
    "\n",
    "for i in range(0, length - lengthSeq, 1):\n",
    "    seq = text[i:i + lengthSeq]\n",
    "    label = text[i + lengthSeq]\n",
    "    x.append([charToNum[word] for word in seq])\n",
    "    y.append(charToNum[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xMOD = np.reshape(x, (len(x), lengthSeq, 1))\n",
    "xMOD = xMOD / float(len(chars))\n",
    "yMOD = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 - 22s - 1s/step - loss: 6.9094\n",
      "Epoch 2/10\n",
      "21/21 - 18s - 835ms/step - loss: 6.5083\n",
      "Epoch 3/10\n",
      "21/21 - 19s - 887ms/step - loss: 6.4472\n",
      "Epoch 4/10\n",
      "21/21 - 21s - 1s/step - loss: 6.4248\n",
      "Epoch 5/10\n",
      "21/21 - 21s - 990ms/step - loss: 6.4174\n",
      "Epoch 6/10\n",
      "21/21 - 20s - 976ms/step - loss: 6.4180\n",
      "Epoch 7/10\n",
      "21/21 - 22s - 1s/step - loss: 6.4169\n",
      "Epoch 8/10\n",
      "21/21 - 20s - 966ms/step - loss: 6.4070\n",
      "Epoch 9/10\n",
      "21/21 - 20s - 957ms/step - loss: 6.4113\n",
      "Epoch 10/10\n",
      "21/21 - 21s - 989ms/step - loss: 6.4085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35d25d090>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(xMOD.shape[1], xMOD.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(yMOD.shape[1], activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "model.fit(xMOD, yMOD, epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stringMapped \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lengthSeq):\n\u001b[1;32m      3\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(stringMapped,(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stringMapped), \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "stringMapped = x[5]\n",
    "for i in range(lengthSeq):\n",
    "    x = np.reshape(stringMapped,(1, len(stringMapped), 1))\n",
    "    x = x / float(len(chars))\n",
    "    predictIndex = np.argmax(model.predict(x, verbose=0))\n",
    "    sequence = [numToChar[value] for value in stringMapped]\n",
    "    stringMapped.append(predictIndex)\n",
    "    stringMapped = stringMapped[1:len(stringMapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so i, made lame by fortune's dearest spite, take all my comfort of thy worth and truth; for whether beauty, birth, or wealth, or wit, or any of these all, or all, or more, entitled in thy parts, do crowned sit, i make my love engrafted, to this store: so then i am not lame, poor, nor despis'd, whilst that this shadow doth such substance give that i in thy abundance am suffic'd, and by a part of all thy glory live. look what is best, that best i wish in thee: this wish i have; then ten times happy\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
